{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv; import numpy as np\n",
    "import re\n",
    "\n",
    "path = '/Users/andiedonovan/myProjects/Youtube_Python_Project/AndiesBranch/'\n",
    "os.chdir(path) # change directory\n",
    "\n",
    "# load in data\n",
    "\n",
    "# training data\n",
    "okgo = pd.read_csv('data/OKGO.csv', delimiter=\";\", skiprows=2, encoding='latin-1', engine='python') # read in the data\n",
    "trump = pd.read_csv('data/trump.csv', delimiter=\",\", skiprows=2, encoding='utf-8', error_bad_lines=False, engine='python')\n",
    "swift = pd.read_csv('data/TaylorSwift.csv', delimiter=\",\", skiprows=2, nrows=180, encoding='utf-8', engine='python')\n",
    "royal = pd.read_csv('data/RoyalWedding.csv', delimiter=\",\", skiprows=2, nrows=61, encoding='utf-8', engine='python')\n",
    "paul = pd.read_csv('data/LoganPaul.csv', delimiter=\",\", skiprows=2, nrows=200, encoding='utf-8', engine='python')\n",
    "blogs = pd.read_csv('data/Kagel.csv', delimiter=\",\", skiprows=2, encoding='latin-1', engine='python') # read in the data\n",
    "tweets = pd.read_csv('data/twitter.csv', delimiter=\",\", skiprows=2, encoding='latin-1', engine='python') # read in the data\n",
    "\n",
    "# test data:\n",
    "#trump = pd.read_csv('data/trump.csv', delimiter=\"@@@\", skiprows=2, encoding='utf-8', error_bad_lines=False, engine='python')\n",
    "# combine training dataframes\n",
    "df = pd.read_csv('data/data.csv', delimiter=\"@@@\", skiprows=2, encoding='utf-8', engine='python')\n",
    "\n",
    "# clean dataframes\n",
    "tweets = tweets.drop(['Topic', 'TweetId', \"TweetDate\"], axis = 1).dropna()\n",
    "\n",
    "def fix_cols(DF):\n",
    "    DF = DF.iloc[:,:2]\n",
    "    DF.columns = [\"label\", \"comment\"]\n",
    "    return DF\n",
    "\n",
    "okgo = fix_cols(okgo)\n",
    "trump = fix_cols(trump)\n",
    "swift = fix_cols(swift)\n",
    "royal = fix_cols(royal)\n",
    "paul = fix_cols(paul)\n",
    "data = fix_cols(data)\n",
    "tweets = fix_cols(tweets)\n",
    "\n",
    "tweets.label = tweets.label.replace({'positive': '1.0', 'negative':'-1.0', 'neutral': '0.0', 'irrelevant': '0.0'}, regex=True)\n",
    "tweets['label'] = pd.to_numeric(tweets['label'], errors='coerce')\n",
    "\n",
    "videos = pd.concat([okgo, trump, swift, royal, paul], ignore_index=True)\n",
    "data = videos.copy()\n",
    "\n",
    "df.columns = [\"comment\", \"label\"]\n",
    "\n",
    "#DataList = [videos, full, videos_not_royal, videos_not_okgo]\n",
    "#excluded = [okgo, royal]\n",
    "\n",
    "# clean up textual data (remove symbols)\n",
    "def AsStr(DF):\n",
    "    DF[\"comment\"]= DF[\"comment\"].astype(str)\n",
    "\n",
    "AsStr(data)\n",
    "AsStr(df)\n",
    "\n",
    "def cleanerFn(b):\n",
    "    for row in range(len(b)):\n",
    "        line = b.loc[row, \"comment\"]\n",
    "        b.loc[row,\"comment\"] = re.sub(\"[^a-zA-Z]\", \" \", line)\n",
    "\n",
    "def cleanerFn2(b):\n",
    "    for row in range(len(b)):\n",
    "        line = b.iloc[row, 1]\n",
    "        b.iloc[row,1] = re.sub(\"[^a-zA-Z]\", \" \", line)\n",
    "\n",
    "cleanerFn(df)\n",
    "cleanerFn2(data)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "import sklearn # machine learning\n",
    "from sklearn.model_selection import train_test_split # splitting up data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "def nlpFunction(a):\n",
    "    a['com_token']=a['comment'].str.lower().str.split()\n",
    "    a['com_remv']=a['com_token'].apply(lambda x: [y for y in x if y not in sw])\n",
    "    a[\"com_lemma\"] = a['com_remv'].apply(lambda x : [lemmatizer.lemmatize(y) for y in x]) # lemmatization\n",
    "    a['com_stem']=a['com_lemma'].apply(lambda x : [ps.stem(y) for y in x]) # stemming\n",
    "    a[\"com_stem_str\"] = a[\"com_stem\"].apply(', '.join)\n",
    "    return a\n",
    "\n",
    "df = nlpFunction(df)\n",
    "data = nlpFunction(data)\n",
    "trump = nlpFunction(trump)\n",
    "\n",
    "X_train = data[\"com_stem_str\"]\n",
    "X_test = trump[\"com_stem_str\"]\n",
    "Y_train = data[\"label\"]\n",
    "Y_test = trump[\"label\"]\n",
    "X_user = df[\"com_stem_str\"]\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "xtrain = tfidf.fit_transform(X_train) # transform and fit training data\n",
    "xtest = tfidf.transform(X_test) # transform test data from fitted transformer\n",
    "xuser = tfidf.transform(X_user)\n",
    "data_trans= tfidf.transform(data[\"com_stem_str\"]) # transform entire dataset for cross validation\n",
    "df_trans = tfidf.transform(df[\"com_stem_str\"])\n",
    "\n",
    "'''X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                                    df[\"com_stem_str\"], df[\"label\"],\n",
    "                                    test_size=0.25,\n",
    "                                    random_state=42)'''\n",
    "\n",
    "\n",
    "# running models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm # support vector machine\n",
    "from sklearn import metrics # for accuracy/ precision\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier # Stochastic Gradient Descent\n",
    "from sklearn.neighbors import KNeighborsClassifier # k-NN ensemble method\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rs = 10\n",
    "lr = LogisticRegression(solver='sag', max_iter=100, random_state=rs, multi_class=\"multinomial\")\n",
    "mnb = MultinomialNB()\n",
    "svm = svm.SVC()\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=rs)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "models = ['lr', 'mnb', 'svm', 'rf', 'knn']\n",
    "labels = ['label_' + str(models[i]) for i in range(0,len(models))]\n",
    "predictions = [str(models[i])+\"_predict\" for i in range(0,len(models))]\n",
    "d = {}\n",
    "initModels = [lr, mnb, svm, rf, knn]\n",
    "\n",
    "for i in range(0,5):\n",
    "    initModels[i].fit(xtrain, Y_train)\n",
    "    d[predictions[i]] = initModels[i].predict(xuser)\n",
    "\n",
    "    # Create table of prediction accuracy rates\n",
    "Table = pd.DataFrame(columns=['comment', 'label_lr', 'label_mnb', 'label_svm', 'label_rf', 'label_knn'])\n",
    "for i in range(0, len(models)):\n",
    "    Table[labels[i]] = d[predictions[i]]\n",
    "Table[\"comment\"] = df[\"comment\"]\n",
    "\n",
    "# Create table of predicted sentiment ratios\n",
    "Ratios = pd.DataFrame(columns=['label_lr', 'label_mnb', 'label_svm', 'label_rf', 'label_knn'],\n",
    "    index=range(0,3))\n",
    "def RatioFinder(model):\n",
    "    pos = Table[Table[model]== 1.0]\n",
    "    neg = Table[Table[model]== -1.0]\n",
    "    neu = Table[Table[model]== 0.0]\n",
    "\n",
    "    pos_len = len(pos); neg_len = len(neg); neu_len = len(neu)\n",
    "    total = pos_len + neg_len + neu_len\n",
    "\n",
    "    neg_ratio = round(neg_len / float(total), 2) * 100\n",
    "    pos_ratio = round(pos_len / float(total), 2) * 100\n",
    "    neu_ratio = round(neu_len / float(total), 2) * 100\n",
    "\n",
    "    ratios = [pos_ratio, neu_ratio, neg_ratio]\n",
    "    return ratios\n",
    "\n",
    "for i in range(0,3):\n",
    "        for j in range(0,5):\n",
    "            Ratios.iloc[i,j] = RatioFinder(labels[j])[i]\n",
    "\n",
    "all_models = pd.DataFrame(columns=['average'], index=range(0,3))\n",
    "all_models[\"average\"]= Ratios.mean(axis=1)\n",
    "\n",
    "# set the prediction to the mode of the row\n",
    "Table[\"Prediction\"] = 0\n",
    "Table[\"Prediction\"] = Table[['label_lr','label_mnb','label_svm','label_rf','label_knn']].mode(axis=1)\n",
    "df.label = Table[\"Prediction\"]\n",
    "\n",
    "# extracting comments for each label\n",
    "df[\"com_remv\"] = df[\"com_remv\"].apply(', '.join)\n",
    "df[\"com_remv\"] = df[\"com_remv\"].str.replace(\",\",\"\").astype(str)\n",
    "\n",
    "'''df_words = df[[\"label\",\"com_remv\"]]\n",
    "positive = df_words[df_words[\"label\"]==1.0]\n",
    "neutral = df_words[df_words[\"label\"]==0.0]\n",
    "negative = df_words[df_words[\"label\"]==-1.0]\n",
    "'''\n",
    "p = df[df[\"label\"]==1]\n",
    "positive = p[\"com_remv\"]\n",
    "n = df[df[\"label\"]==-1]\n",
    "negative = n[\"com_remv\"]\n",
    "ne = df[df[\"label\"]==0]\n",
    "neutral = ne[\"com_remv\"]\n",
    "\n",
    "# most frequent words in each label\n",
    "most_freq_pos = pd.Series(' '.join(positive).lower().split()).value_counts()[:10]\n",
    "most_freq_neg = pd.Series(' '.join(negative).lower().split()).value_counts()[:10]\n",
    "most_freq_neu = pd.Series(' '.join(neutral).lower().split()).value_counts()[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash; import os\n",
    "from dash.dependencies import Input, Output, Event\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly; import flask\n",
    "import glob; import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import sys; import csv\n",
    "import pandas as pd; import base64\n",
    "\n",
    "path = '/Users/andiedonovan/myProjects/Youtube_Python_Project/AndiesBranch/'\n",
    "\n",
    "#os.chdir(path + 'images/')\n",
    "#image_filename = 'wordcloud.png' # replace with your own image\n",
    "#encoded_image = base64.b64encode(open(image_filename, 'rb').read())\n",
    "\n",
    "'''os.chdir(path + 'dash/')\n",
    "data = UD.data # user loaded dataset\n",
    "df = UD.df # labeled dataset\n",
    "all_models = UD.all_models # table of average model results for % pos, neg, neu\n",
    "Ratios = UD.Ratios # % pos, neg, neu for each model\n",
    "Table = UD.Table # classification for each comment by model\n",
    "'''\n",
    "model_options = ['label_lr', 'label_mnb', 'label_svm', 'label_rf', 'label_knn']\n",
    "\n",
    "mydict = {'label_lr': 'Logistic Regression', 'label_mnb':'Multinomial Naive Bayes',\n",
    "'label_svm':'Support Vector Machine', 'label_rf': 'Random Forest', 'label_knn': 'K-Nearest Neighbor'}\n",
    "\n",
    "#img_file = '/Users/andiedonovan/myProjects/Youtube_Python_Project/AndiesBranch/images/wordcloud.png'\n",
    "#encoded_image = base64.b64encode(open(img_file, 'rb').read())\n",
    "#image_filename = '/Users/andiedonovan/myProjects/Youtube_Python_Project/AndiesBranch/images/wordcloud.png' # replace with your own image\n",
    "#encoded_image = base64.b64encode(open(image_filename, 'rb').read())\n",
    "#image_directory = '/Users/andiedonovan/myProjects/Youtube_Python_Project/AndiesBranch/images/wordcloud.png'\n",
    "#list_of_images = [os.path.basename(x) for x in glob.glob('{}*.png'.format(image_directory))]\n",
    "#static_image_route = '/static/'\n",
    "\n",
    "'''colors = {\n",
    "    'background': 'white',\n",
    "    'graph_background': 'white',\n",
    "    'text': 'purple',\n",
    "    'subtext': 'black',\n",
    "    'blue_pal': 'lightskyblue',\n",
    "    'red_pal': 'lightroal',\n",
    "    'yellow_pal': 'yellowgreen',\n",
    "    'grey_pal': 'lightgrey'\n",
    "}'''\n",
    "\n",
    "# colors2 = ['#FEBFB3', '#E1396C', '#96D38C', '#D0F9B1']\n",
    "#colors2 = ['#B8F7D4', '#835AF1', '#7FA6EE', '#FEBFB3']\n",
    "colors3 = [\"#009999\", '#BFD8BD', '#9C7CA5', '#ADB2D3']\n",
    "# #835AF1 dark blue\n",
    "# #7FA6EE light blue\n",
    "# #B8F7D4 green\n",
    "\n",
    "# extracting comments for each label\n",
    "'''positive = UD.positive\n",
    "negative = UD.negative\n",
    "neutral = UD.neutral\n",
    "\n",
    "# most frequent words in each label\n",
    "most_freq_pos = UD.most_freq_pos\n",
    "most_freq_neg = UD.most_freq_neg\n",
    "most_freq_neu = UD.most_freq_neu'''\n",
    "\n",
    "# word frequency bar plot\n",
    "Positive = go.Bar(\n",
    "            x = most_freq_pos.index,\n",
    "            y = most_freq_pos.values,\n",
    "            name=\"Positive\",\n",
    "            marker=dict(color=colors3[0])\n",
    "        )\n",
    "Neutral = go.Bar(\n",
    "            x = most_freq_neu.index,\n",
    "            y = most_freq_neu.values,\n",
    "            name=\"Neutral\",\n",
    "            marker=dict(color=colors3[1])\n",
    "        )\n",
    "Negative = go.Bar(\n",
    "            x = most_freq_neg.index,\n",
    "            y = most_freq_neg.values,\n",
    "            name=\"Negative\",\n",
    "            marker=dict(color=colors3[2])\n",
    "        )\n",
    "\n",
    "updatemenus = list([\n",
    "\n",
    "            dict(type=\"buttons\",\n",
    "                 active=-1,\n",
    "                 buttons=list([\n",
    "                    dict(label = 'Positive',\n",
    "                         method = 'update',\n",
    "                         args = [{'visible': [True, False, False]},\n",
    "                                 {'title': 'Positive Comments'}]\n",
    "                        ),\n",
    "                    dict(label = 'Neutral',\n",
    "                         method = 'update',\n",
    "                         args = [{'visible': [False, True, False]},\n",
    "                                 {'title': 'Neutral Comments'}]\n",
    "                        ),\n",
    "                    dict(label = 'Negative',\n",
    "                         method = 'update',\n",
    "                         args = [{'visible': [False, False, True]},\n",
    "                                 {'title': 'Negative Comments'}]\n",
    "                        ),\n",
    "                    dict(label = 'All',\n",
    "                         method = 'update',\n",
    "                         args = [{'visible': [True, True, True, True]},\n",
    "                                 {'title': 'All Comments'}]\n",
    "                        )\n",
    "                 ]),\n",
    "                    pad= {'r': 15, 't': 10},\n",
    "                )\n",
    "        ])\n",
    "\n",
    "def generate_table(dataframe, max_rows=10):\n",
    "    return html.Table(\n",
    "        [html.Tr([html.Th(col) for col in dataframe.columns])] +\n",
    "        [html.Tr([\n",
    "            html.Td(dataframe.iloc[i][col]) for col in dataframe.columns\n",
    "        ]) for i in range(min(len(dataframe), max_rows))]\n",
    "    )\n",
    "\n",
    "app = dash.Dash()\n",
    "\n",
    "'''\n",
    "-----------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Video Input Line\n",
    "    dcc.Input(id='video-input', value='Enter Youtube video URL here', type='text',\n",
    "        style={\n",
    "                'position': 'relative',\n",
    "                'width': '600px',\n",
    "                'float': 'center',\n",
    "                'display': 'inline-block'},\n",
    "                ),\n",
    "\n",
    "    html.Div(id='video-input-div',\n",
    "        style={\n",
    "                'position': 'relative',\n",
    "                'width': '600px',\n",
    "                'float': 'center',\n",
    "                'display': 'inline-block'},\n",
    "                ),\n",
    "'''\n",
    "\n",
    "app.layout = html.Div([\n",
    "\n",
    "# Header\n",
    "    html.H1(children='A YouTube Web App',\n",
    "        style={\n",
    "            'padding': '10px',\n",
    "            'text-align': 'center',\n",
    "            'font-size': '40px'}\n",
    "        ),\n",
    "\n",
    "# Pie Chart\n",
    "    html.Div(\n",
    "        [\n",
    "            dcc.Dropdown(\n",
    "                id=\"MyModel\",\n",
    "                options=[{\n",
    "                    'label': mydict.get(str(i)),\n",
    "                    'value': i\n",
    "                } for i in model_options],\n",
    "                value='All Models'),\n",
    "            dcc.Graph(id='pie-graph')\n",
    "        ],\n",
    "            style={\n",
    "                'float': 'left',\n",
    "                'width': '40.00%',\n",
    "                'padding': '10px 10px 10px 0px',\n",
    "                'height': '300px'}\n",
    "        ),\n",
    "\n",
    "# Bar Chart; Right\n",
    "    html.Div([\n",
    "        dcc.Graph(\n",
    "                id='bar-graph',\n",
    "                figure={\n",
    "                    'data': [Positive, Neutral, Negative],\n",
    "                    'layout': go.Layout(title='Most Common Words', barmode='stack', showlegend=True,\n",
    "                            updatemenus=updatemenus)\n",
    "                        },\n",
    "                style={\n",
    "                'float': 'right',\n",
    "                'width': '55.00%',\n",
    "                'padding': '42px 0px 10px 10px',\n",
    "                'height': '500px'\n",
    "                }\n",
    "                )\n",
    "            ]),\n",
    "    #html.H2(\"WordCloud\"),\n",
    "    #html.Img(src='data:image/png;base64,{}'.format(encoded_image)),\n",
    "\n",
    "    #html.Img(src='/Users/andiedonovan/myProjects/Youtube_Python_Project/AndiesBranch/images/wordcloud.png',\n",
    "    #    style={'width': '500px'})\n",
    "    #html.Img(src='data:image/png;base64,{}'.format(encoded_image))\n",
    "    html.Div([\n",
    "        dcc.Dropdown(\n",
    "            id='my-table-dropdown',\n",
    "            options=[{'label': i, 'value': i}\n",
    "            for i in ['All Comments', 'Positive', 'Negative', 'Neutral']\n",
    "            ],value=None),\n",
    "        html.Div(id='table-container')\n",
    "        ],\n",
    "            style={'width': '49%',\n",
    "            'display': 'inline-block',\n",
    "            'padding': '0 20'}\n",
    "            ),\n",
    "])\n",
    "\n",
    "'''\n",
    "-----------------------------------------------------------------\n",
    "'''\n",
    "'''\n",
    "    html.Div([\n",
    "        dcc.Graph(\n",
    "            id='bubble',\n",
    "\n",
    "            figure={\n",
    "            'data': go.Scatter(\n",
    "                x = most_freq_neu.index,\n",
    "                y = -1.0,\n",
    "                name=\"Neutral\",\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=most_freq_neu.values,\n",
    "                    color='#7FA6EE'))\n",
    "            },\n",
    "\n",
    "            style={\n",
    "                'float': 'right',\n",
    "                'width': '55.00%',\n",
    "                'padding': '42px 0px 10px 10px',\n",
    "                'height': '500px'\n",
    "                }\n",
    "            )\n",
    "        ])\n",
    "'''\n",
    "\n",
    "# pie chart\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('pie-graph', 'figure'),\n",
    "    [dash.dependencies.Input('MyModel', 'value')])\n",
    "def update_graph(MyModel):\n",
    "    if MyModel == \"All Models\":\n",
    "        values = [.2,.3,.5]\n",
    "    else:\n",
    "        values = list(Ratios[str(MyModel)])\n",
    "\n",
    "    trace = go.Pie(labels=[\"Positive\", \"Negative\",\"Neutral\"], values=values, hole=.2,\n",
    "        name='MyModel', hoverinfo='label+percent',\n",
    "        textinfo='label + value',textfont=dict(size=20),\n",
    "        marker=dict(colors= colors3))\n",
    "\n",
    "    return {\n",
    "        'data': [trace],\n",
    "        'layout':\n",
    "        go.Layout(\n",
    "            title='Sentiment Ratios as Predicted by {}'.format(MyModel)\n",
    "            )\n",
    "    }\n",
    "\n",
    "'''my_css_url = \"https://github.com/adonovan7/YoutubeAnalysis/blob/master/dash/dash.css\"\n",
    "app.css.append_css({\n",
    "    \"external_url\": my_css_url\n",
    "})\n",
    "'''\n",
    "\n",
    "# table of comments\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('table-container', 'children'),\n",
    "    [dash.dependencies.Input('my-table-dropdown', 'value')])\n",
    "def table_update(value):\n",
    "    simple_df = data[[\"label\",\"comment\"]]\n",
    "    selected = {\"Positive\": 1.0, \"Neutral\": 0.0, \"Negative\": -1.0}\n",
    "    if value != \"All Comments\":\n",
    "        filtered_df = simple_df[simple_df[\"label\"]==selected.get(value)]\n",
    "    else:\n",
    "         filtered_df = simple_df\n",
    "    return generate_table(filtered_df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
